{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x176f00af048>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env.reset()\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "plt.imshow(env.render(\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # n_of_frames for each game \n",
    "npop = 100 # population size\n",
    "sigma= 0.1 # deviation \n",
    "w = np.random.randn(4) # probabilities of action_0 on each frame ## to update!\n",
    "alpha =0.1 #learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(w_new):\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    s = env.reset()\n",
    "    rewards= []\n",
    "    for j in range(N):\n",
    "        prob = np.clip(np.dot(w_new.T,s),0,1)\n",
    "        p = [prob,1.-prob]\n",
    "        new_state, r, done, _ = env.step(np.random.choice(n_actions,p = p))\n",
    "        rewards.append(r)\n",
    "        s=new_state\n",
    "        if done:\n",
    "            break\n",
    "    return sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train(w):\n",
    "    for n_episodes in range(1000):\n",
    "        R=[]\n",
    "        w_try = np.random.randn(npop,4) \n",
    "    \n",
    "        for i in range(npop):\n",
    "            w_new=w + sigma*w_try[i]\n",
    "            R.append(training(w_new))\n",
    "        if n_episodes%10 == 0: print('episode of game {}, mean reward over population {}'\n",
    "                                .format(n_episodes, np.mean(R)))\n",
    "        if np.mean(R) > 195: \n",
    "            print('iteration {} mean reward over population {}'.format(n_episodes,np.mean(R)))\n",
    "            break\n",
    "        R = (R-np.mean(R))/(1+np.std(R))\n",
    "        w += alpha/(npop*sigma)* np.dot(w_try.T,R)   \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode of game 0, mean reward over population 24.14\n",
      "episode of game 10, mean reward over population 39.74\n",
      "episode of game 20, mean reward over population 47.7\n",
      "episode of game 30, mean reward over population 50.4\n",
      "episode of game 40, mean reward over population 55.65\n",
      "episode of game 50, mean reward over population 64.92\n",
      "episode of game 60, mean reward over population 61.97\n",
      "episode of game 70, mean reward over population 63.68\n",
      "episode of game 80, mean reward over population 63.01\n",
      "episode of game 90, mean reward over population 71.33\n",
      "episode of game 100, mean reward over population 78.94\n",
      "episode of game 110, mean reward over population 73.48\n",
      "episode of game 120, mean reward over population 68.07\n",
      "episode of game 130, mean reward over population 70.2\n",
      "episode of game 140, mean reward over population 108.32\n",
      "episode of game 150, mean reward over population 139.05\n",
      "episode of game 160, mean reward over population 173.31\n",
      "iteration 162 mean reward over population 199.58\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_new = full_train(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # n_of_frames for each game \n",
    "npop = 100 # population size\n",
    "sigma= 0.1 # deviation \n",
    "w = np.random.randn(4) # probabilities of action_0 on each frame ## to update!\n",
    "alpha =0.1 #learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_parallel(w_new):\n",
    "    env = gym.make(\"CartPole-v0\").env\n",
    "    s = env.reset()\n",
    "    rewards= []\n",
    "    for j in range(N):\n",
    "        prob = np.clip(np.dot(w_new.T,s),0,1)\n",
    "        p = [prob,1.-prob]\n",
    "        new_state, r, done, _ = env.step(np.random.choice(n_actions,p = p))\n",
    "        rewards.append(r)\n",
    "        s=new_state\n",
    "        if done:\n",
    "            break\n",
    "    return sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train_parallel(w):\n",
    "    for n_episodes in range(1000):\n",
    "        w_try = np.random.randn(npop,4) \n",
    "        R = Parallel(n_jobs=4)(delayed(training_parallel)(w+sigma*w_try[i]) for i in range(npop))\n",
    "        \n",
    "        if n_episodes%10 == 0: print('episode of game {}, mean reward over population {}'\n",
    "                                .format(n_episodes, np.mean(R)))\n",
    "        if np.mean(R) > 195: \n",
    "            print('iteration {} mean reward over population {}'.format(n_episodes,np.mean(R)))\n",
    "            break\n",
    "        R = (R-np.mean(R))/(1+np.std(R))\n",
    "        w += alpha/(npop*sigma)* np.dot(w_try.T,R)    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode of game 0, mean reward over population 20.29\n",
      "episode of game 10, mean reward over population 31.98\n",
      "episode of game 20, mean reward over population 38.4\n",
      "episode of game 30, mean reward over population 42.98\n",
      "episode of game 40, mean reward over population 48.24\n",
      "episode of game 50, mean reward over population 47.46\n",
      "episode of game 60, mean reward over population 45.61\n",
      "episode of game 70, mean reward over population 46.96\n",
      "episode of game 80, mean reward over population 44.1\n",
      "episode of game 90, mean reward over population 46.69\n",
      "episode of game 100, mean reward over population 48.07\n",
      "episode of game 110, mean reward over population 46.88\n",
      "episode of game 120, mean reward over population 51.67\n",
      "episode of game 130, mean reward over population 53.57\n",
      "episode of game 140, mean reward over population 57.51\n",
      "episode of game 150, mean reward over population 57.57\n",
      "episode of game 160, mean reward over population 59.13\n",
      "episode of game 170, mean reward over population 58.96\n",
      "episode of game 180, mean reward over population 60.49\n",
      "episode of game 190, mean reward over population 63.14\n",
      "episode of game 200, mean reward over population 61.32\n",
      "episode of game 210, mean reward over population 61.97\n",
      "episode of game 220, mean reward over population 60.45\n",
      "episode of game 230, mean reward over population 61.54\n",
      "episode of game 240, mean reward over population 62.73\n",
      "episode of game 250, mean reward over population 66.58\n",
      "episode of game 260, mean reward over population 62.79\n",
      "episode of game 270, mean reward over population 69.43\n",
      "episode of game 280, mean reward over population 66.06\n",
      "episode of game 290, mean reward over population 73.3\n",
      "episode of game 300, mean reward over population 68.93\n",
      "episode of game 310, mean reward over population 70.69\n",
      "episode of game 320, mean reward over population 64.36\n",
      "episode of game 330, mean reward over population 74.15\n",
      "episode of game 340, mean reward over population 71.88\n",
      "episode of game 350, mean reward over population 78.17\n",
      "episode of game 360, mean reward over population 86.59\n",
      "episode of game 370, mean reward over population 87.58\n",
      "episode of game 380, mean reward over population 92.23\n",
      "episode of game 390, mean reward over population 96.68\n",
      "episode of game 400, mean reward over population 109.7\n",
      "episode of game 410, mean reward over population 121.25\n",
      "episode of game 420, mean reward over population 155.17\n",
      "episode of game 430, mean reward over population 182.44\n",
      "episode of game 440, mean reward over population 186.31\n",
      "iteration 441 mean reward over population 205.3\n",
      "Wall time: 47.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w_new = full_train_parallel(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
